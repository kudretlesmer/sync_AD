{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "from itertools import accumulate\n",
    "import utilities\n",
    "import synchronization_heads.synchronization_utils as synchronization_utils\n",
    "from synchronization_heads.synchronization import SynchronizationBlock, DesynchronizationBlock\n",
    "import synchronization_heads.synchronization\n",
    "from fusing_models.PMCE import PMCE\n",
    "from fusing_models.RMCE import RMCE\n",
    "import copy\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Reload modules (only when necessary, e.g., during development)\n",
    "def reload_modules():\n",
    "    import synchronization_heads.synchronization\n",
    "    import fusing_models.PMCE\n",
    "    import fusing_models.RMCE\n",
    "    import importlib\n",
    "    importlib.reload(synchronization_heads.synchronization)\n",
    "    importlib.reload(fusing_models.PMCE)\n",
    "    importlib.reload(fusing_models.RMCE)\n",
    "    # Custom Libraries\n",
    "    import synchronization_heads.synchronization_utils as synchronization_utils\n",
    "    import utilities\n",
    "    from synchron_ad import SynchronMaskEstimator\n",
    "    from synchronization_heads.synchronization import SynchronizationBlock, DesynchronizationBlock\n",
    "    from fusing_models.PMCE import PMCE\n",
    "    from fusing_models.RMCE import RMCE\n",
    "\n",
    "\n",
    "#reload_modules()\n",
    "# Call reload_modules() only when you need to refresh imports.\n",
    "# reload_modules()\n",
    "\n",
    "# Plotting Constants\n",
    "WIDTH = 18\n",
    "HEIGHT = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_dataloaders(PARAMS):\n",
    "    # Paths to the training and testing HDF5 dataset files\n",
    "    TRAIN_DATASET_PATH = f'data/{PARAMS[\"machine\"]}/windowed/train_dataset_window_0.100s.h5'\n",
    "    TEST_DATASET_PATH = f'data/{PARAMS[\"machine\"]}/windowed/test_dataset_window_0.100s.h5'\n",
    "\n",
    "\n",
    "\n",
    "    # List of label names to be extracted from the dataset\n",
    "    LABEL_NAMES = ['segment_id',\n",
    "                'split_label',\n",
    "                'anomaly_label',\n",
    "                'domain_shift_op',\n",
    "                'domain_shift_env']\n",
    "\n",
    "    # Load the dataset\n",
    "    X_train_raw, Y_train_raw, X_test, Y_test = utilities.load_dataset(\n",
    "        TRAIN_DATASET_PATH, TEST_DATASET_PATH, LABEL_NAMES, PARAMS[\"sensors\"])\n",
    "\n",
    "    # Set the seed for general torch operations\n",
    "    torch.manual_seed(PARAMS['seed'])\n",
    "    # Set the seed for MPS torch operations (ones that happen on the MPS Apple GPU)\n",
    "\n",
    "    if PARAMS['device'] == 'mps':\n",
    "        torch.mps.manual_seed(PARAMS['seed'])\n",
    "    elif PARAMS['device'] == 'cuda':\n",
    "        torch.cuda.manual_seed(PARAMS['seed'])\n",
    "    elif PARAMS['device'] == 'cpu':\n",
    "        torch.manual_seed(PARAMS['seed'])\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported device type: {PARAMS['device']}\")\n",
    "\n",
    "\n",
    "    # Load the dataset\n",
    "    X_train_raw, Y_train_raw, X_test, Y_test = utilities.load_dataset(\n",
    "        TRAIN_DATASET_PATH, TEST_DATASET_PATH, LABEL_NAMES, PARAMS[\"sensors\"])\n",
    "\n",
    "    # Combine anomaly labels and domain shift labels to form a combined label\n",
    "    Y_train_raw['combined_label'] = Y_train_raw['anomaly_label'] + \\\n",
    "        Y_train_raw['domain_shift_op'] + Y_train_raw['domain_shift_env']\n",
    "    Y_test['combined_label'] = Y_test['anomaly_label'] + \\\n",
    "        Y_test['domain_shift_op'] + Y_test['domain_shift_env']\n",
    "\n",
    "    # Split training data into training and validation sets, maintaining the\n",
    "    # stratified distribution of the combined label\n",
    "    train_indices, valid_indices, _, _ = train_test_split(\n",
    "        range(len(Y_train_raw)),\n",
    "        Y_train_raw,\n",
    "        stratify=Y_train_raw['combined_label'],\n",
    "        test_size=PARAMS['valid_size'],\n",
    "        random_state=PARAMS['seed']\n",
    "    )\n",
    "\n",
    "    # Select the training and validation data based on the indices\n",
    "    X_train = [sensor_data[train_indices] for sensor_data in X_train_raw]\n",
    "    X_valid = [sensor_data[valid_indices] for sensor_data in X_train_raw]\n",
    "    Y_train = Y_train_raw.iloc[train_indices].reset_index(drop=True)\n",
    "    Y_valid = Y_train_raw.iloc[valid_indices].reset_index(drop=True)\n",
    "\n",
    "    # Normalize the training, validation, and test datasets using the\n",
    "    # specified normalization method\n",
    "    X_train, X_valid, X_test = utilities.normalize_data(\n",
    "        X_train, X_valid, X_test, PARAMS['normalisation'])\n",
    "\n",
    "    # Extract the number of channels and window lengths for each sensor\n",
    "    NUM_CHANNELS = {PARAMS[\"sensors\"][i]: x.shape[1] for i, x in enumerate(X_train)}\n",
    "    WINDOW_LENGTHS = {PARAMS[\"sensors\"][i]: x.shape[2] for i, x in enumerate(X_train)}\n",
    "\n",
    "\n",
    "    X_train_tensor = [torch.from_numpy(x) for x in X_train]\n",
    "    X_valid_tensor = [torch.from_numpy(x) for x in X_valid]\n",
    "    X_test_tensor = [torch.from_numpy(x) for x in X_test]\n",
    "\n",
    "    train_dataset = utilities.CustomDataset(X_train_tensor)\n",
    "    valid_dataset = utilities.CustomDataset(X_valid_tensor)\n",
    "    test_dataset = utilities.CustomDataset(X_test_tensor)\n",
    "\n",
    "    train_data_loader = DataLoader(\n",
    "        train_dataset, batch_size=PARAMS['batch_size'], shuffle=True)\n",
    "    valid_data_loader = DataLoader(\n",
    "        valid_dataset, batch_size=PARAMS['batch_size'], shuffle=False)\n",
    "    test_data_loader = DataLoader(\n",
    "        test_dataset, batch_size=PARAMS['batch_size'], shuffle=False)\n",
    "    \n",
    "    return train_data_loader, valid_data_loader, test_data_loader, Y_test, NUM_CHANNELS, WINDOW_LENGTHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBuilder:\n",
    "    def __init__(self, PARAMS, sync_head_conv_parameters):\n",
    "        \"\"\"\n",
    "        Initializes the model builder with parameters and references.\n",
    "\n",
    "        Args:\n",
    "            PARAMS (dict): Dictionary with model hyperparameters.\n",
    "            sync_head_conv_parameters (dict): Additional params for sync_head_conv if used.\n",
    "        \"\"\"\n",
    "        self.PARAMS = PARAMS\n",
    "        self.sync_head_conv_parameters = sync_head_conv_parameters\n",
    "    \n",
    "    def build_synchronization_block(self):\n",
    "        \"\"\"\n",
    "        Builds and returns a synchronization block based on PARAMS.\n",
    "        \"\"\"\n",
    "        return SynchronizationBlock(\n",
    "            params=self.PARAMS,\n",
    "            sensors=self.PARAMS[\"sensors\"],\n",
    "            window_lengths=self.PARAMS[\"WINDOW_LENGTHS\"],\n",
    "            num_channels=self.PARAMS[\"NUM_CHANNELS\"],\n",
    "            c_sync=self.PARAMS['C_sync'],\n",
    "            synchronization_method=self.PARAMS['synchronization_method'],\n",
    "            fc_num_layers=self.PARAMS['fc_num_layers'],\n",
    "            sync_head_conv_parameters=self.sync_head_conv_parameters\n",
    "        )\n",
    "\n",
    "    def build_desynchronization_block(self):\n",
    "        \"\"\"\n",
    "        Builds and returns a desynchronization block based on PARAMS.\n",
    "        \"\"\"\n",
    "        return DesynchronizationBlock(\n",
    "            params=self.PARAMS,\n",
    "            sensors=self.PARAMS[\"sensors\"],\n",
    "            num_channels=self.PARAMS[\"NUM_CHANNELS\"],\n",
    "            window_lengths=self.PARAMS[\"WINDOW_LENGTHS\"],\n",
    "            c_sync=self.PARAMS['C_sync'],\n",
    "            desynchronization_method=self.PARAMS['desynchronization_method'],\n",
    "            fc_num_layers=self.PARAMS['fc_num_layers'],\n",
    "            sync_head_conv_parameters=self.sync_head_conv_parameters,\n",
    "        )\n",
    "\n",
    "    def build_fusing_block(self):\n",
    "        \"\"\"\n",
    "        Builds and returns a fusing block based on PARAMS.\n",
    "        \"\"\"\n",
    "        return PMCE(\n",
    "            sensors=self.PARAMS[\"sensors\"],\n",
    "            num_channels=self.PARAMS[\"NUM_CHANNELS\"],\n",
    "            c_sync=self.PARAMS['C_sync'],\n",
    "            c_fuse=self.PARAMS['C_fuse'],\n",
    "            kernel_size=self.PARAMS['kernel_size']\n",
    "        )\n",
    "\n",
    "    def build_all_blocks(self):\n",
    "        \"\"\"\n",
    "        Builds and returns all three blocks as a tuple.\n",
    "        \"\"\"\n",
    "        sync_block = self.build_synchronization_block()\n",
    "        desync_block = self.build_desynchronization_block()\n",
    "        fusing_block = self.build_fusing_block()\n",
    "        return sync_block, desync_block, fusing_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Sync & Desync Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sync_and_desync_block(\n",
    "    synchronisation_block,\n",
    "    desynchronisation_block,\n",
    "    train_data_loader,\n",
    "    valid_data_loader,\n",
    "    epochs=100,\n",
    "    patience=4,\n",
    "    lr=0.001,\n",
    "    verbose=True,\n",
    "    device='cpu'\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains the given synchronization and desynchronization blocks \n",
    "    using the provided data loaders.\n",
    "\n",
    "    Args:\n",
    "        synchronisation_block (nn.Module): The sync block to be trained.\n",
    "        desynchronisation_block (nn.Module): The desync block to be trained.\n",
    "        train_data_loader (DataLoader): Dataloader for training data.\n",
    "        valid_data_loader (DataLoader): Dataloader for validation data.\n",
    "        epochs (int): Number of training epochs.\n",
    "        patience (int): Early stopping patience (in epochs).\n",
    "        lr (float): Learning rate.\n",
    "        verbose (bool): Prints progress messages if True.\n",
    "        device (str): Device to place the model and data on. \n",
    "                      e.g., 'cuda' or 'cpu'.\n",
    "\n",
    "    Returns:\n",
    "        (list, list): (train_losses_epoch, valid_losses_epoch) \n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.Adam(\n",
    "        list(synchronisation_block.parameters()) \n",
    "        + list(desynchronisation_block.parameters()), lr=lr\n",
    "    )\n",
    "\n",
    "    # Move modules to device\n",
    "    synchronisation_block.to(device)\n",
    "    desynchronisation_block.to(device)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    non_improving_count = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    train_losses_epoch = []\n",
    "    valid_losses_epoch = []\n",
    "\n",
    "    # Main loop\n",
    "    for epoch in range(epochs):\n",
    "        if verbose:\n",
    "            print(f\"\\n----------- Epoch {epoch + 1} -----------\")\n",
    "\n",
    "        # --- Training ---\n",
    "        synchronisation_block.train()\n",
    "        desynchronisation_block.train()\n",
    "\n",
    "        total_train_loss = 0.0\n",
    "        train_loader_tqdm = tqdm.tqdm(train_data_loader, desc=f\"Train Epoch {epoch+1}\", leave=True)\n",
    "\n",
    "        for batch_idx, x_batch in enumerate(train_loader_tqdm):\n",
    "            x_batch = [x.to(device) for x in x_batch]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            synced_output = synchronisation_block(x_batch)\n",
    "            desynced_output = desynchronisation_block(synced_output)\n",
    "\n",
    "            # Calculate MSE across all sensors\n",
    "            sensor_losses = torch.cat([\n",
    "                ((x_in - x_out) ** 2).mean(dim=(0, 2))\n",
    "                for x_in, x_out in zip(x_batch, desynced_output)\n",
    "            ])\n",
    "            loss = sensor_losses.mean()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            avg_train_loss = total_train_loss / (batch_idx + 1)\n",
    "            train_loader_tqdm.set_postfix({'Train_loss': avg_train_loss})\n",
    "\n",
    "        train_losses_epoch.append(avg_train_loss)\n",
    "\n",
    "        # --- Validation ---\n",
    "        synchronisation_block.eval()\n",
    "        desynchronisation_block.eval()\n",
    "\n",
    "        total_valid_loss = 0.0\n",
    "        valid_loader_tqdm = tqdm.tqdm(valid_data_loader, desc=f\"Valid Epoch {epoch+1}\", leave=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, x_batch in enumerate(valid_loader_tqdm):\n",
    "                x_batch = [x.to(device) for x in x_batch]\n",
    "\n",
    "                synced_output = synchronisation_block(x_batch)\n",
    "                desynced_output = desynchronisation_block(synced_output)\n",
    "\n",
    "                sensor_losses = torch.cat([\n",
    "                    ((x_in - x_out) ** 2).mean(dim=(0, 2))\n",
    "                    for x_in, x_out in zip(x_batch, desynced_output)\n",
    "                ])\n",
    "                loss = sensor_losses.mean()\n",
    "\n",
    "                total_valid_loss += loss.item()\n",
    "                avg_val_loss = total_valid_loss / (batch_idx + 1)\n",
    "                valid_loader_tqdm.set_postfix({'Valid_loss': avg_val_loss})\n",
    "\n",
    "        valid_losses_epoch.append(avg_val_loss)\n",
    "\n",
    "        # --- Early Stopping ---\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            non_improving_count = 0\n",
    "            # Save best state\n",
    "            best_model_state = {\n",
    "                'synchronisation_block': synchronisation_block.state_dict(),\n",
    "                'desynchronisation_block': desynchronisation_block.state_dict(),\n",
    "                'epoch': epoch + 1,\n",
    "                'best_loss': best_loss\n",
    "            }\n",
    "        else:\n",
    "            non_improving_count += 1\n",
    "            if non_improving_count > patience:\n",
    "                if verbose:\n",
    "                    print(\"Stopping early due to no improvement in validation loss.\")\n",
    "                break\n",
    "\n",
    "    # Load best model if found\n",
    "    if best_model_state is not None:\n",
    "        synchronisation_block.load_state_dict(best_model_state['synchronisation_block'])\n",
    "        desynchronisation_block.load_state_dict(best_model_state['desynchronisation_block'])\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"Loaded best model from epoch {best_model_state['epoch']} \"\n",
    "                f\"with val_loss = {best_model_state['best_loss']:.4f}\"\n",
    "            )\n",
    "\n",
    "    return train_losses_epoch, valid_losses_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FusionTrainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusionTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        synchronisation_block,\n",
    "        fusing_block,\n",
    "        desynchronisation_block,\n",
    "        device,\n",
    "        lr=1e-4,\n",
    "        epochs=100,\n",
    "        train_sync=False,\n",
    "        patience=10\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Manages training/validation of the fusing block,\n",
    "        optionally also trains the synchronization & desynchronization blocks.\n",
    "\n",
    "        Args:\n",
    "            synchronisation_block (nn.Module): Synchronization block.\n",
    "            fusing_block (nn.Module): Fusion block.\n",
    "            desynchronisation_block (nn.Module): Desynchronization block.\n",
    "            device (torch.device): Device (e.g., 'cuda' or 'cpu').\n",
    "            lr (float): Learning rate.\n",
    "            epochs (int): Number of epochs.\n",
    "            train_sync (bool): Whether to train the synchronization & desync blocks.\n",
    "            patience (int): Number of epochs to wait for improvement in val loss \n",
    "                            before early stopping.\n",
    "        \"\"\"\n",
    "        self.synchronisation_block = synchronisation_block\n",
    "        self.fusing_block = fusing_block\n",
    "        self.desynchronisation_block = desynchronisation_block\n",
    "        \n",
    "        self.device = device\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.train_sync = train_sync\n",
    "        self.patience = patience\n",
    "\n",
    "        # Freeze/unfreeze sync + desync based on train_sync\n",
    "        # (If train_sync = False, these blocks get frozen.)\n",
    "        freeze_module_parameters(self.synchronisation_block, freeze=not self.train_sync)\n",
    "        freeze_module_parameters(self.desynchronisation_block, freeze=not self.train_sync)\n",
    "\n",
    "        # Move models to device\n",
    "        self.synchronisation_block.to(self.device)\n",
    "        self.fusing_block.to(self.device)\n",
    "        self.desynchronisation_block.to(self.device)\n",
    "\n",
    "        # Prepare optimizer parameters\n",
    "        # Always optimize the fusing block\n",
    "        params_to_optimize = list(self.fusing_block.parameters())\n",
    "        # If training sync, also optimize sync + desync\n",
    "        if self.train_sync:\n",
    "            params_to_optimize += list(self.synchronisation_block.parameters())\n",
    "            params_to_optimize += list(self.desynchronisation_block.parameters())\n",
    "\n",
    "        # Define optimizer\n",
    "        self.optimizer = torch.optim.Adam(params_to_optimize, lr=self.lr)\n",
    "\n",
    "        # For logging\n",
    "        self.train_losses_epoch = []\n",
    "        self.valid_losses_epoch = []\n",
    "\n",
    "    def fit(self, train_data_loader, valid_data_loader):\n",
    "        \"\"\"\n",
    "        Trains the fusing block (and optionally the sync + desync blocks), end-to-end.\n",
    "        Implements early stopping and reloads the best model state at the end.\n",
    "        \"\"\"\n",
    "        best_val_loss = float(\"inf\")\n",
    "        no_improvement_count = 0\n",
    "        best_model_state = None\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            # -----------------------\n",
    "            # TRAINING PHASE\n",
    "            # -----------------------\n",
    "            total_train_loss = 0.0\n",
    "            train_loader_tqdm = tqdm.tqdm(\n",
    "                train_data_loader, \n",
    "                desc=f\"Train Epoch {epoch+1}\", \n",
    "                leave=True\n",
    "            )\n",
    "\n",
    "            # Set modes:\n",
    "            self.fusing_block.train()  # Always training the fusing block\n",
    "            if self.train_sync:\n",
    "                # If we are training sync + desync:\n",
    "                self.synchronisation_block.train()\n",
    "                self.desynchronisation_block.train()\n",
    "            else:\n",
    "                # Otherwise, keep them in eval mode\n",
    "                self.synchronisation_block.eval()\n",
    "                self.desynchronisation_block.eval()\n",
    "\n",
    "            for batch_idx, x_batch in enumerate(train_loader_tqdm):\n",
    "                x_batch = [x.to(self.device) for x in x_batch]\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # 1) Synchronize\n",
    "                synched = self.synchronisation_block(x_batch)  # list-of-tensors in => typically list or combined out\n",
    "                # 2) Fuse\n",
    "                fused = self.fusing_block(synched)\n",
    "\n",
    "                if self.train_sync:\n",
    "                    # If training sync/desync: reconstruct back and compare to original\n",
    "                    x_batch_output = self.desynchronisation_block(fused)\n",
    "                    # Compute reconstruction loss across all sensors\n",
    "                    # (shape: (batch, channels, length))\n",
    "                    sensor_losses = torch.cat([\n",
    "                        ((x_sensor - x_sensor_out) ** 2).mean(dim=(0, 2))\n",
    "                        for x_sensor, x_sensor_out in zip(x_batch, x_batch_output)\n",
    "                    ])\n",
    "                else:\n",
    "                    # Not training sync/desync => do a direct MSE(synched, fused)\n",
    "                    # (this only updates the fusing block unless blocks are not actually frozen)\n",
    "                    sensor_losses = ((synched - fused) ** 2).mean(dim=(0, 2))\n",
    "\n",
    "                loss = sensor_losses.mean()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                total_train_loss += loss.item()\n",
    "                avg_train_loss = total_train_loss / (batch_idx + 1)\n",
    "                train_loader_tqdm.set_postfix({'Train_loss': avg_train_loss})\n",
    "\n",
    "            self.train_losses_epoch.append(avg_train_loss)\n",
    "\n",
    "            # -----------------------\n",
    "            # VALIDATION PHASE\n",
    "            # -----------------------\n",
    "            total_valid_loss = 0.0\n",
    "            valid_loader_tqdm = tqdm.tqdm(\n",
    "                valid_data_loader, \n",
    "                desc=f\"Valid Epoch {epoch+1}\", \n",
    "                leave=True\n",
    "            )\n",
    "\n",
    "            # Eval mode for validation\n",
    "            self.fusing_block.eval()\n",
    "            self.synchronisation_block.eval()\n",
    "            self.desynchronisation_block.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, x_batch in enumerate(valid_loader_tqdm):\n",
    "                    x_batch = [x.to(self.device) for x in x_batch]\n",
    "\n",
    "                    synched = self.synchronisation_block(x_batch)\n",
    "                    fused = self.fusing_block(synched)\n",
    "\n",
    "                    if self.train_sync:\n",
    "                        # Reconstruct\n",
    "                        x_batch_output = self.desynchronisation_block(fused)\n",
    "                        sensor_losses = torch.cat([\n",
    "                            ((x_sensor - x_sensor_out) ** 2).mean(dim=(0, 2))\n",
    "                            for x_sensor, x_sensor_out in zip(x_batch, x_batch_output)\n",
    "                        ])\n",
    "                    else:\n",
    "                        # Compare synched vs fused\n",
    "                        sensor_losses = ((synched - fused) ** 2).mean(dim=(0, 2))\n",
    "\n",
    "                    loss = sensor_losses.mean()\n",
    "\n",
    "                    total_valid_loss += loss.item()\n",
    "                    avg_val_loss = total_valid_loss / (batch_idx + 1)\n",
    "                    valid_loader_tqdm.set_postfix({'Valid_loss': avg_val_loss})\n",
    "\n",
    "            self.valid_losses_epoch.append(avg_val_loss)\n",
    "\n",
    "            # -----------------------\n",
    "            # EARLY STOPPING LOGIC\n",
    "            # -----------------------\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                no_improvement_count = 0\n",
    "                # Save best model weights\n",
    "                best_model_state = {\n",
    "                    \"fusing_block\": copy.deepcopy(self.fusing_block.state_dict())\n",
    "                }\n",
    "                if self.train_sync:\n",
    "                    best_model_state[\"synchronisation_block\"] = copy.deepcopy(self.synchronisation_block.state_dict())\n",
    "                    best_model_state[\"desynchronisation_block\"] = copy.deepcopy(self.desynchronisation_block.state_dict())\n",
    "            else:\n",
    "                no_improvement_count += 1\n",
    "\n",
    "            if no_improvement_count >= self.patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "        # -----------------------\n",
    "        # RELOAD BEST MODEL STATE\n",
    "        # -----------------------\n",
    "        if best_model_state is not None:\n",
    "            self.fusing_block.load_state_dict(best_model_state[\"fusing_block\"])\n",
    "            if self.train_sync:\n",
    "                self.synchronisation_block.load_state_dict(best_model_state[\"synchronisation_block\"])\n",
    "                self.desynchronisation_block.load_state_dict(best_model_state[\"desynchronisation_block\"])\n",
    "        \n",
    "        return self.train_losses_epoch, self.valid_losses_epoch\n",
    "\n",
    "    def predict(self, data_loader):\n",
    "        \"\"\"\n",
    "        Generates predictions (synched and fused outputs) on new data.\n",
    "        \n",
    "        Returns:\n",
    "            all_synched (torch.Tensor): Concatenated synchronized outputs.\n",
    "            all_fused   (torch.Tensor): Concatenated fused outputs.\n",
    "        \"\"\"\n",
    "        self.fusing_block.eval()\n",
    "        self.synchronisation_block.eval()\n",
    "        self.desynchronisation_block.eval()  # if you need desync in the prediction pipeline, handle similarly\n",
    "\n",
    "        if self.train_sync:\n",
    "            all_input = []\n",
    "            all_output = []\n",
    "\n",
    "        else:    \n",
    "            all_synched = []\n",
    "            all_fused = []\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x_batch in tqdm.tqdm(data_loader, desc=\"Predicting\", leave=True):\n",
    "                x_batch = [x.to(self.device) for x in x_batch]\n",
    "                synched = self.synchronisation_block(x_batch)\n",
    "                fused = self.fusing_block(synched)\n",
    "\n",
    "                if self.train_sync:\n",
    "                    output = self.desynchronisation_block(fused)\n",
    "                    for i in range(len(output)):\n",
    "                        if len(all_input) <= i:\n",
    "                            all_input.append([])\n",
    "                            all_output.append([])\n",
    "                        all_input[i].append(x_batch[i])\n",
    "                        all_output[i].append(output[i])\n",
    "                else:\n",
    "                    all_synched.append(synched)\n",
    "                    all_fused.append(fused)\n",
    "\n",
    "        if self.train_sync:\n",
    "            # Concatenate results across batches\n",
    "            for i in range(len(all_input)):\n",
    "                all_input[i] = torch.cat(all_input[i], dim=0)\n",
    "                all_output[i] = torch.cat(all_output[i], dim=0)\n",
    "            return all_input, all_output\n",
    "        else:\n",
    "            # Concatenate results across batches\n",
    "            all_synched = torch.cat(all_synched, dim=0)\n",
    "            all_fused = torch.cat(all_fused, dim=0)\n",
    "            return all_synched, all_fused\n",
    "    \n",
    "def freeze_module_parameters(module, freeze=True):\n",
    "    \"\"\"\n",
    "    Helper function to freeze or unfreeze parameters in a PyTorch module.\n",
    "    \"\"\"\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = not freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(PARAMS):\n",
    "    Experiment_name = f\"{PARAMS['machine']}-{PARAMS['synchronization_method']}-{PARAMS['pre_train_sync']}-{PARAMS['post_train_sync']}-{PARAMS['lambda']}\"\n",
    "    # create a dictionary with name  experiments/Experiment_name\n",
    "    os.makedirs(f\"experiments/{Experiment_name}\", exist_ok=True)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 1. Initialize the data loaders and sync_head_conv parameters\n",
    "    # ---------------------------------------------------------\n",
    "\n",
    "    train_data_loader, valid_data_loader, test_data_loader, Y_test, NUM_CHANNELS, WINDOW_LENGTHS =initialise_dataloaders(PARAMS)\n",
    "\n",
    "    PARAMS['WINDOW_LENGTHS'] = WINDOW_LENGTHS\n",
    "    PARAMS['NUM_CHANNELS'] = NUM_CHANNELS\n",
    "\n",
    "    sync_head_conv_parameters = synchronization_utils.initialize_parameters(SENSORS=PARAMS[\"sensors\"], \n",
    "                                                                            WINDOW_LENGTHS=PARAMS['WINDOW_LENGTHS'],\n",
    "                                                                            NUM_CHANNELS=PARAMS['NUM_CHANNELS'], \n",
    "                                                                            lambda_=PARAMS['lambda'])\n",
    "    L_common = sync_head_conv_parameters[PARAMS[\"sensors\"][0]]['input_2']\n",
    "    PARAMS[\"L_common\"] = L_common\n",
    "\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2. Build models using the ModelBuilder\n",
    "    # ---------------------------------------------------------\n",
    "    builder = ModelBuilder(\n",
    "        PARAMS, \n",
    "        sync_head_conv_parameters\n",
    "    )\n",
    "    synchronisation_block, desynchronisation_block, fusing_block = builder.build_all_blocks()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3. Optionally, train the sync & desync blocks\n",
    "    # ---------------------------------------------------------\n",
    "    if PARAMS['pre_train_sync']:\n",
    "        train_losses, valid_losses = train_sync_and_desync_block(\n",
    "            synchronisation_block,\n",
    "            desynchronisation_block,\n",
    "            train_data_loader=train_data_loader,\n",
    "            valid_data_loader=valid_data_loader,\n",
    "            epochs=PARAMS['epochs'],\n",
    "            patience=PARAMS['patience'],\n",
    "            lr=PARAMS['lr'],\n",
    "            verbose=True,\n",
    "            device=PARAMS['device']\n",
    "        )\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 4. Train the fusing block using FusionTrainer\n",
    "    #    (train_sync=False if you don't want to re-train sync)\n",
    "    # ---------------------------------------------------------\n",
    "    trainer = FusionTrainer(\n",
    "        synchronisation_block=synchronisation_block,\n",
    "        fusing_block=fusing_block,\n",
    "        desynchronisation_block=desynchronisation_block,\n",
    "        train_sync=PARAMS['post_train_sync'],\n",
    "        epochs=PARAMS['epochs'],\n",
    "        patience=PARAMS['patience'],\n",
    "        lr=PARAMS['lr'],\n",
    "        device=PARAMS['device'],\n",
    "    )\n",
    "\n",
    "    train_losses_epoch, valid_losses_epoch = trainer.fit(train_data_loader, valid_data_loader)\n",
    "    PARAMS['train_losses_epoch'] = train_losses_epoch\n",
    "    PARAMS['valid_losses_epoch'] = valid_losses_epoch\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 5. Predict on new data\n",
    "    # ---------------------------------------------------------\n",
    "    synched_outputs, fused_outputs = trainer.predict(test_data_loader)\n",
    "\n",
    "    # save models block\n",
    "    torch.save(synchronisation_block.state_dict(), f\"experiments/{Experiment_name}/synchronisation_block.pth\")\n",
    "    torch.save(desynchronisation_block.state_dict(), f\"experiments/{Experiment_name}/desynchronisation_block.pth\")\n",
    "    torch.save(fusing_block.state_dict(), f\"experiments/{Experiment_name}/fusing_block.pth\")\n",
    "\n",
    "    # Define the file path where you want to save the JSON file\n",
    "    json_file_path = f'experiments/{Experiment_name}/PARAMS.json'\n",
    "\n",
    "    # Convert all int64 values to int\n",
    "    PARAMS = {key: int(value) if isinstance(value, np.integer) else value for key, value in PARAMS.items()}\n",
    "    # Write the PARAMS dictionary to the JSON file\n",
    "    with open(json_file_path, 'w') as json_file:\n",
    "        json.dump(PARAMS, json_file, indent=4)\n",
    "\n",
    "    print(f\"PARAMS have been written to {json_file_path}\")\n",
    "    # Calculate the mean squared error between fused and synchronized outputs\n",
    "    \n",
    "    \n",
    "    if PARAMS['post_train_sync']:\n",
    "        error_list = []\n",
    "        for sensor_idx in range(len(PARAMS[\"sensors\"])):\n",
    "            error_sensor = ((fused_outputs[sensor_idx] - synched_outputs[sensor_idx]) ** 2).mean(dim=2).detach().cpu().numpy()\n",
    "            error_list.append(error_sensor)\n",
    "        errors_mtx = np.concatenate(error_list, axis=1)\n",
    "\n",
    "    else:\n",
    "        errors_mtx = ((fused_outputs - synched_outputs) ** 2).mean(dim=2).detach().cpu().numpy()  # N, C\n",
    "\n",
    "    # Construct a matrix with proper naming: sensor_name + channel\n",
    "    column_names = [f\"{sensor}_{channel}\" for sensor in PARAMS[\"sensors\"] for channel in range(NUM_CHANNELS[sensor])]\n",
    "\n",
    "    # Create a DataFrame with the errors\n",
    "    error_df = pd.DataFrame(errors_mtx, columns=column_names)\n",
    "\n",
    "    # Concatenate the error DataFrame with the Y_test DataFrame\n",
    "    Y_test_c = pd.concat([Y_test.copy(), error_df], axis=1)\n",
    "\n",
    "    # Group by segment_id and aggregate the error columns\n",
    "    Y_test_c = utilities.group_by_segment_id(Y_test_c, column_names)\n",
    "    AUC_results = []\n",
    "    for col in column_names:\n",
    "        AUC = utilities.calculate_single_auc(Y_test_c,col)\n",
    "        AUC_results.append(AUC)\n",
    "\n",
    "    AUC_results = pd.concat(AUC_results)\n",
    "    AUC_results\n",
    "    AUC_results.to_csv(f\"experiments/{Experiment_name}/AUC_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping ism330dhcx_gyro as it has the same window length as another\n",
      "Optimum window length: 1537, corresponding lambda: 0.7900959561343386\n",
      "For sensor imp23absu_mic there are 84 solutions\n",
      "For sensor ism330dhcx_acc there are 1 solutions\n",
      "For sensor ism330dhcx_gyro there are 1 solutions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1:  16%|█▌        | 73/460 [00:06<00:31, 12.14it/s, Train_loss=1.21]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 68\u001b[0m\n\u001b[1;32m      1\u001b[0m Experiment_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m }\n\u001b[1;32m     65\u001b[0m ]\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m PARAMS \u001b[38;5;129;01min\u001b[39;00m Experiment_list:\n\u001b[0;32m---> 68\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPARAMS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 64\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(PARAMS)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# 4. Train the fusing block using FusionTrainer\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#    (train_sync=False if you don't want to re-train sync)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     53\u001b[0m trainer \u001b[38;5;241m=\u001b[39m FusionTrainer(\n\u001b[1;32m     54\u001b[0m     synchronisation_block\u001b[38;5;241m=\u001b[39msynchronisation_block,\n\u001b[1;32m     55\u001b[0m     fusing_block\u001b[38;5;241m=\u001b[39mfusing_block,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m     device\u001b[38;5;241m=\u001b[39mPARAMS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 64\u001b[0m train_losses_epoch, valid_losses_epoch \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m PARAMS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_losses_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train_losses_epoch\n\u001b[1;32m     66\u001b[0m PARAMS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_losses_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m valid_losses_epoch\n",
      "Cell \u001b[0;32mIn[5], line 122\u001b[0m, in \u001b[0;36mFusionTrainer.fit\u001b[0;34m(self, train_data_loader, valid_data_loader)\u001b[0m\n\u001b[1;32m    119\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 122\u001b[0m total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m total_train_loss \u001b[38;5;241m/\u001b[39m (batch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    124\u001b[0m train_loader_tqdm\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: avg_train_loss})\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Experiment_list = [\n",
    "{\n",
    "    \"device\": \"mps\",\n",
    "    \"seed\": 1995,\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 1000,\n",
    "    \"lr\": 1e-4,\n",
    "    \"patience\": 10,\n",
    "    \"valid_size\": 0.1,\n",
    "    \"normalisation\": \"std_window\",\n",
    "    \"machine\": \"BrushlessMotor\",\n",
    "    \"sensors\": [\"imp23absu_mic\", \"ism330dhcx_acc\", \"ism330dhcx_gyro\"],\n",
    "    \"synchronization_method\": \"sync_head_conv\",  # \"sync_head_conv\", \"sync_head_fc\", \"resample_linear\", \"resample_fft\", \"zeropad\", \"resample_spline\"\n",
    "    \"desynchronization_method\": \"conv\",  # \"conv\", \"fc\"\n",
    "    \"C_sync\": 1,\n",
    "    \"C_fuse\": 4,\n",
    "    \"kernel_size\": 3,\n",
    "    \"fc_num_layers\": 3,\n",
    "    \"pre_train_sync\": False,\n",
    "    \"post_train_sync\": True,\n",
    "    \"lambda\": 1,\n",
    "},\n",
    "{\n",
    "    \"device\": \"mps\",\n",
    "    \"seed\": 1995,\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 1000,\n",
    "    \"lr\": 1e-4,\n",
    "    \"patience\": 10,\n",
    "    \"valid_size\": 0.1,\n",
    "    \"normalisation\": \"std_window\",\n",
    "    \"machine\": \"BrushlessMotor\",\n",
    "    \"sensors\": [\"imp23absu_mic\", \"ism330dhcx_acc\", \"ism330dhcx_gyro\"],\n",
    "    \"synchronization_method\": \"sync_head_conv\",  # \"sync_head_conv\", \"sync_head_fc\", \"resample_linear\", \"resample_fft\", \"zeropad\", \"resample_spline\"\n",
    "    \"desynchronization_method\": \"conv\",  # \"conv\", \"fc\"\n",
    "    \"C_sync\": 1,\n",
    "    \"C_fuse\": 4,\n",
    "    \"kernel_size\": 3,\n",
    "    \"fc_num_layers\": 3,\n",
    "    \"pre_train_sync\": True,\n",
    "    \"post_train_sync\": False,\n",
    "    \"lambda\": 1,\n",
    "},\n",
    "{\n",
    "    \"device\": \"mps\",\n",
    "    \"seed\": 1995,\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 1000,\n",
    "    \"lr\": 1e-4,\n",
    "    \"patience\": 10,\n",
    "    \"valid_size\": 0.1,\n",
    "    \"normalisation\": \"std_window\",\n",
    "    \"machine\": \"BrushlessMotor\",\n",
    "    \"sensors\": [\"imp23absu_mic\", \"ism330dhcx_acc\", \"ism330dhcx_gyro\"],\n",
    "    \"synchronization_method\": \"resample_spline\",  # \"sync_head_conv\", \"sync_head_fc\", \"resample_linear\", \"resample_fft\", \"zeropad\", \"resample_spline\"\n",
    "    \"desynchronization_method\": \"conv\",  # \"conv\", \"fc\"\n",
    "    \"C_sync\": 1,\n",
    "    \"C_fuse\": 4,\n",
    "    \"kernel_size\": 3,\n",
    "    \"fc_num_layers\": 3,\n",
    "    \"pre_train_sync\": False,\n",
    "    \"post_train_sync\": False,\n",
    "    \"lambda\": 1,\n",
    "}\n",
    "]\n",
    "\n",
    "for PARAMS in Experiment_list:\n",
    "    train_model(PARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.random.randint(0, len(test_data_loader.dataset))\n",
    "\n",
    "total_plot = sum([NUM_CHANNELS[sensor] for sensor in PARAMS[\"sensors\"]])\n",
    "plt.close('all')\n",
    "fig, axs = plt.subplots(total_plot, 1, figsize=(\n",
    "    WIDTH, HEIGHT * total_plot * 0.5), sharex=True)\n",
    "\n",
    "i = 0\n",
    "overall_MSE = 0\n",
    "for sensor_idx, sensor in enumerate(PARAMS[\"sensors\"]):\n",
    "    sensor_losses = []\n",
    "    for channel_idx in range(NUM_CHANNELS[sensor]):\n",
    "        if PARAMS['post_train_sync']:\n",
    "            input = synched_outputs[sensor_idx][sample,channel_idx].cpu().numpy()\n",
    "            output = fused_outputs[sensor_idx][sample,channel_idx].detach().cpu().numpy()\n",
    "\n",
    "            # Calculate loss on output\n",
    "            loss_output = ((input - output)**2).mean(0)\n",
    "            sensor_losses.append(f\"{loss_output:.3f}\")\n",
    "\n",
    "            t = np.linspace(0, 1, len(input))\n",
    "\n",
    "            axs[i].plot(t,input, label='Input')\n",
    "            axs[i].plot(t,output, label='Output')\n",
    "\n",
    "        \n",
    "        else:\n",
    "            input = synched_outputs[sample][i].cpu().numpy()\n",
    "            output = fused_outputs[sample][i].detach().cpu().numpy()\n",
    "\n",
    "            # Calculate loss on output\n",
    "            loss_output = ((input - output)**2).mean(0)\n",
    "            sensor_losses.append(f\"{loss_output:.3f}\")\n",
    "\n",
    "            axs[i].plot(input, label='Input')\n",
    "            axs[i].plot(output, label='Output')\n",
    "        i += 1\n",
    "        overall_MSE += loss_output\n",
    "    print(f\"Sensor: {sensor}, Losses on channels: {', '.join(sensor_losses)}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test interpolation methods here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define interpolation methods\n",
    "spline_interp = SynchronizationBlock(\n",
    "    sensors=PARAMS[\"sensors\"],\n",
    "    window_lengths=WINDOW_LENGTHS,\n",
    "    num_channels=NUM_CHANNELS,\n",
    "    c_sync=16,\n",
    "    synchronization_method='resample_spline',\n",
    "    fc_num_layers=1,\n",
    "    sync_head_conv_parameters=sync_head_conv_parameters,\n",
    "    params=PARAMS\n",
    ")\n",
    "\n",
    "linear_interp = SynchronizationBlock(\n",
    "    sensors=PARAMS[\"sensors\"],\n",
    "    window_lengths=WINDOW_LENGTHS,\n",
    "    num_channels=NUM_CHANNELS,\n",
    "    c_sync=16,\n",
    "    synchronization_method='resample_linear',\n",
    "    fc_num_layers=1,\n",
    "    sync_head_conv_parameters=sync_head_conv_parameters,\n",
    "    params=PARAMS\n",
    ")\n",
    "\n",
    "# Select a random sample from the validation dataset\n",
    "sample_idx = np.random.randint(0, len(valid_data_loader.dataset))\n",
    "X_sample = valid_data_loader.dataset[sample_idx:sample_idx+1]\n",
    "\n",
    "# Apply interpolation methods\n",
    "X_spline = spline_interp(X_sample)\n",
    "X_linear = linear_interp(X_sample)\n",
    "\n",
    "# Plot the results\n",
    "total_channels = sum(NUM_CHANNELS.values())\n",
    "plt.close('all')\n",
    "fig, axs = plt.subplots(total_channels, 1, figsize=(WIDTH, HEIGHT * total_channels * 0.5), sharex=True)\n",
    "\n",
    "i = 0\n",
    "for sensor_idx, sensor in enumerate(PARAMS[\"sensors\"]):\n",
    "    for channel_idx in range(NUM_CHANNELS[sensor]):\n",
    "        t_input = np.linspace(0, 1, WINDOW_LENGTHS[sensor])\n",
    "        input_data = X_sample[sensor_idx][0, channel_idx].cpu().numpy()\n",
    "\n",
    "        t_spline = np.linspace(0, 1, X_spline[0][i].shape[0])\n",
    "        output_spline = X_spline[0][i].detach().cpu().numpy()\n",
    "\n",
    "        t_linear = np.linspace(0, 1, X_linear[0][i].shape[0])\n",
    "        output_linear = X_linear[0][i].detach().cpu().numpy()\n",
    "\n",
    "        axs[i].plot(t_input, input_data, label='Input')\n",
    "        axs[i].plot(t_spline, output_spline, label='Output Spline')\n",
    "        axs[i].plot(t_linear, output_linear, label='Output Linear')\n",
    "        i += 1\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
