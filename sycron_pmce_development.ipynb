{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "from itertools import accumulate\n",
    "from synchron_ad import SynchronMaskEstimator\n",
    "\n",
    "\n",
    "# custom\n",
    "import utilities\n",
    "import synchronization_heads.synchronization_utils as synchronization_utils \n",
    "import torch.nn.functional as F\n",
    "\n",
    "# plotting\n",
    "WIDTH = 12\n",
    "HEIGHT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE = 'BrushlessMotor' # BrushlessMotor, RoboticArm\n",
    "# Paths to the training and testing HDF5 dataset files\n",
    "TRAIN_DATASET_PATH = f'data/{MACHINE}/windowed/train_dataset_window_0.100s.h5'\n",
    "TEST_DATASET_PATH = f'data/{MACHINE}/windowed/test_dataset_window_0.100s.h5'\n",
    "\n",
    "# List of sensor names to be extracted from the dataset\n",
    "SENSORS = [\n",
    "    'imp23absu_mic',\n",
    "    'ism330dhcx_acc',\n",
    "    'ism330dhcx_gyro'\n",
    "]\n",
    "\n",
    "# List of label names to be extracted from the dataset\n",
    "LABEL_NAMES = ['segment_id',\n",
    "               'split_label',\n",
    "               'anomaly_label',\n",
    "               'domain_shift_op',\n",
    "               'domain_shift_env']\n",
    "\n",
    "\n",
    "PARAMS = {\n",
    "    'batch_size': 64,\n",
    "    'num_epochs': 1000,\n",
    "    'lr': 0.001,\n",
    "    # TO BE ADAPTED TO YOUR MACHINE: either 'mps or 'cuda' if GPU available,\n",
    "    # otherwise 'cpu'\n",
    "    'device': 'mps',\n",
    "    'patience': 3,\n",
    "    'normalisation': 'std_window',\n",
    "    'valid_size': 0.1,\n",
    "    'seed': 1995,\n",
    "}\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "X_train_raw, Y_train_raw, X_test, Y_test = utilities.load_dataset(\n",
    "    TRAIN_DATASET_PATH, TEST_DATASET_PATH, LABEL_NAMES, SENSORS)\n",
    "\n",
    "# Set the seed for general torch operations\n",
    "torch.manual_seed(PARAMS['seed'])\n",
    "# Set the seed for MPS torch operations (ones that happen on the MPS Apple GPU)\n",
    "\n",
    "if PARAMS['device'] == 'mps':\n",
    "    torch.mps.manual_seed(PARAMS['seed'])\n",
    "elif PARAMS['device'] == 'cuda':\n",
    "    torch.cuda.manual_seed(PARAMS['seed'])\n",
    "elif PARAMS['device'] == 'cpu':\n",
    "    torch.manual_seed(PARAMS['seed'])\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported device type: {PARAMS['device']}\")\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "X_train_raw, Y_train_raw, X_test, Y_test = utilities.load_dataset(\n",
    "    TRAIN_DATASET_PATH, TEST_DATASET_PATH, LABEL_NAMES, SENSORS)\n",
    "\n",
    "# Combine anomaly labels and domain shift labels to form a combined label\n",
    "Y_train_raw['combined_label'] = Y_train_raw['anomaly_label'] + \\\n",
    "    Y_train_raw['domain_shift_op'] + Y_train_raw['domain_shift_env']\n",
    "Y_test['combined_label'] = Y_test['anomaly_label'] + \\\n",
    "    Y_test['domain_shift_op'] + Y_test['domain_shift_env']\n",
    "\n",
    "# Split training data into training and validation sets, maintaining the\n",
    "# stratified distribution of the combined label\n",
    "train_indices, valid_indices, _, _ = train_test_split(\n",
    "    range(len(Y_train_raw)),\n",
    "    Y_train_raw,\n",
    "    stratify=Y_train_raw['combined_label'],\n",
    "    test_size=PARAMS['valid_size'],\n",
    "    random_state=PARAMS['seed']\n",
    ")\n",
    "\n",
    "# Select the training and validation data based on the indices\n",
    "X_train = [sensor_data[train_indices] for sensor_data in X_train_raw]\n",
    "X_valid = [sensor_data[valid_indices] for sensor_data in X_train_raw]\n",
    "Y_train = Y_train_raw.iloc[train_indices].reset_index(drop=True)\n",
    "Y_valid = Y_train_raw.iloc[valid_indices].reset_index(drop=True)\n",
    "\n",
    "# Normalize the training, validation, and test datasets using the\n",
    "# specified normalization method\n",
    "X_train, X_valid, X_test = utilities.normalize_data(\n",
    "    X_train, X_valid, X_test, PARAMS['normalisation'])\n",
    "\n",
    "# Extract the number of channels and window lengths for each sensor\n",
    "NUM_CHANNELS = {SENSORS[i]: x.shape[1] for i, x in enumerate(X_train)}\n",
    "WINDOW_LENGTHS = {SENSORS[i]: x.shape[2] for i, x in enumerate(X_train)}\n",
    "\n",
    "\n",
    "X_train_tensor = [torch.from_numpy(x) for x in X_train]\n",
    "X_valid_tensor = [torch.from_numpy(x) for x in X_valid]\n",
    "X_test_tensor = [torch.from_numpy(x) for x in X_test]\n",
    "\n",
    "train_dataset = utilities.CustomDataset(X_train_tensor)\n",
    "valid_dataset = utilities.CustomDataset(X_valid_tensor)\n",
    "test_dataset = utilities.CustomDataset(X_test_tensor)\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset, batch_size=PARAMS['batch_size'], shuffle=True)\n",
    "valid_data_loader = DataLoader(\n",
    "    valid_dataset, batch_size=PARAMS['batch_size'], shuffle=False)\n",
    "test_data_loader = DataLoader(\n",
    "    test_dataset, batch_size=PARAMS['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the lambda parameter\n",
    "lambda_ = 0.8\n",
    "sync_head_conv_parameters = synchronization_utils.initialize_parameters(\n",
    "    SENSORS, WINDOW_LENGTHS, NUM_CHANNELS, lambda_=lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import synchron_ad\n",
    "importlib.reload(synchron_ad)\n",
    "from synchron_ad import SynchronMaskEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_sync = 1\n",
    "C_fuse = 16\n",
    "kernel_size = 3\n",
    "model = SynchronMaskEstimator(sensors=SENSORS,\n",
    "                              num_channels=NUM_CHANNELS,\n",
    "                              window_lengths=WINDOW_LENGTHS,\n",
    "                              c_sync=C_sync,\n",
    "                              c_fuse=C_fuse,\n",
    "                              kernel_size=kernel_size,\n",
    "                              params=PARAMS,\n",
    "                              sync_method='sync_head_conv',# 'sync_head_conv', 'sync_head_fc' , 'resample_interp', 'resample_fft', 'zeropad'\n",
    "                              sync_head_conv_parameters=sync_head_conv_parameters,\n",
    "                              projection_method='conv', # 'fc' or 'conv',\n",
    "                              fc_num_layers=1\n",
    "                              ).to(PARAMS['device'])\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=PARAMS['lr'])\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")\n",
    "# Calculate number of trainable parameters\n",
    "trainable_params = sum(p.numel()\n",
    "                       for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total number of trainable parameters: {trainable_params}\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data_loader, valid_data_loader, optimizer, PARAMS['num_epochs'], PARAMS['patience'],verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, outputs = model.predict(test_data_loader)\n",
    "labels = Y_test['combined_label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute MSE of normal and 1 masked sensor version\n",
    "sensor_losses = torch.cat([((x_sensor - x_sensor_out)**2).mean(0).mean(1)\n",
    "                          for x_sensor, x_sensor_out in zip(inputs, outputs)]).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.random.randint(0, len(inputs[0]))\n",
    "total_plot = sum([NUM_CHANNELS[sensor] for sensor in SENSORS])\n",
    "plt.close('all')\n",
    "fig, axs = plt.subplots(total_plot, 1, figsize=(\n",
    "    WIDTH, HEIGHT * total_plot * 0.5), sharex=True)\n",
    "\n",
    "i = 0\n",
    "overall_MSE = 0\n",
    "for sensor_idx, sensor in enumerate(SENSORS):\n",
    "    sensor_losses = []\n",
    "    for channel_idx in range(NUM_CHANNELS[sensor]):\n",
    "        t = np.linspace(0, 1, WINDOW_LENGTHS[sensor])\n",
    "        input = inputs[sensor_idx][sample, channel_idx].cpu().numpy()\n",
    "        output = outputs[sensor_idx][sample, channel_idx].detach().cpu().numpy()\n",
    "        # Calculate loss on output\n",
    "        loss_output = ((input - output)**2).mean(0)\n",
    "        sensor_losses.append(f\"{loss_output:.3f}\")\n",
    "\n",
    "        axs[i].plot(t, input, label='Input')\n",
    "        axs[i].plot(t, output, label='Output')\n",
    "        i += 1\n",
    "        overall_MSE += loss_output\n",
    "    print(f\"Sensor: {sensor}, Losses on channels: {', '.join(sensor_losses)}\")\n",
    "\n",
    "print(f\"Label: {labels[sample]} Overall MSE: {overall_MSE:.3f}\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
