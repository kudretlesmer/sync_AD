{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import datetime\n",
    "import tqdm\n",
    "from itertools import accumulate\n",
    "\n",
    "\n",
    "# custom\n",
    "import utilities\n",
    "import sync_head_utils \n",
    "import torch.nn.functional as F\n",
    "\n",
    "# plotting\n",
    "WIDTH = 12\n",
    "HEIGHT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE = 'BrushlessMotor' # BrushlessMotor, RoboticArm\n",
    "# Paths to the training and testing HDF5 dataset files\n",
    "TRAIN_DATASET_PATH = f'data/{MACHINE}/windowed/train_dataset_window_0.100s.h5'\n",
    "TEST_DATASET_PATH = f'data/{MACHINE}/windowed/test_dataset_window_0.100s.h5'\n",
    "\n",
    "# List of sensor names to be extracted from the dataset\n",
    "SENSORS = [\n",
    "    'imp23absu_mic',\n",
    "    'ism330dhcx_acc',\n",
    "    'ism330dhcx_gyro'\n",
    "]\n",
    "\n",
    "# List of label names to be extracted from the dataset\n",
    "LABEL_NAMES = ['segment_id',\n",
    "               'split_label',\n",
    "               'anomaly_label',\n",
    "               'domain_shift_op',\n",
    "               'domain_shift_env']\n",
    "\n",
    "\n",
    "PARAMS = {\n",
    "    'batch_size': 64,\n",
    "    'num_epochs': 1000,\n",
    "    'lr': 0.001,\n",
    "    # TO BE ADAPTED TO YOUR MACHINE: either 'mps or 'cuda' if GPU available,\n",
    "    # otherwise 'cpu'\n",
    "    'device': 'mps',\n",
    "    'patience': 3,\n",
    "    'normalisation': 'std_window',\n",
    "    'valid_size': 0.1,\n",
    "    'seed': 1995,\n",
    "}\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "X_train_raw, Y_train_raw, X_test, Y_test = utilities.load_dataset(\n",
    "    TRAIN_DATASET_PATH, TEST_DATASET_PATH, LABEL_NAMES, SENSORS)\n",
    "\n",
    "# Set the seed for general torch operations\n",
    "torch.manual_seed(PARAMS['seed'])\n",
    "# Set the seed for MPS torch operations (ones that happen on the MPS Apple GPU)\n",
    "\n",
    "if PARAMS['device'] == 'mps':\n",
    "    torch.mps.manual_seed(PARAMS['seed'])\n",
    "elif PARAMS['device'] == 'cuda':\n",
    "    torch.cuda.manual_seed(PARAMS['seed'])\n",
    "elif PARAMS['device'] == 'cpu':\n",
    "    torch.manual_seed(PARAMS['seed'])\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported device type: {PARAMS['device']}\")\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "X_train_raw, Y_train_raw, X_test, Y_test = utilities.load_dataset(\n",
    "    TRAIN_DATASET_PATH, TEST_DATASET_PATH, LABEL_NAMES, SENSORS)\n",
    "\n",
    "# Combine anomaly labels and domain shift labels to form a combined label\n",
    "Y_train_raw['combined_label'] = Y_train_raw['anomaly_label'] + \\\n",
    "    Y_train_raw['domain_shift_op'] + Y_train_raw['domain_shift_env']\n",
    "Y_test['combined_label'] = Y_test['anomaly_label'] + \\\n",
    "    Y_test['domain_shift_op'] + Y_test['domain_shift_env']\n",
    "\n",
    "# Split training data into training and validation sets, maintaining the\n",
    "# stratified distribution of the combined label\n",
    "train_indices, valid_indices, _, _ = train_test_split(\n",
    "    range(len(Y_train_raw)),\n",
    "    Y_train_raw,\n",
    "    stratify=Y_train_raw['combined_label'],\n",
    "    test_size=PARAMS['valid_size'],\n",
    "    random_state=PARAMS['seed']\n",
    ")\n",
    "\n",
    "# Select the training and validation data based on the indices\n",
    "X_train = [sensor_data[train_indices] for sensor_data in X_train_raw]\n",
    "X_valid = [sensor_data[valid_indices] for sensor_data in X_train_raw]\n",
    "Y_train = Y_train_raw.iloc[train_indices].reset_index(drop=True)\n",
    "Y_valid = Y_train_raw.iloc[valid_indices].reset_index(drop=True)\n",
    "\n",
    "# Normalize the training, validation, and test datasets using the\n",
    "# specified normalization method\n",
    "X_train, X_valid, X_test = utilities.normalize_data(\n",
    "    X_train, X_valid, X_test, PARAMS['normalisation'])\n",
    "\n",
    "# Extract the number of channels and window lengths for each sensor\n",
    "NUM_CHANNELS = {SENSORS[i]: x.shape[1] for i, x in enumerate(X_train)}\n",
    "WINDOW_LENGTHS = {SENSORS[i]: x.shape[2] for i, x in enumerate(X_train)}\n",
    "\n",
    "\n",
    "X_train_tensor = [torch.from_numpy(x) for x in X_train]\n",
    "X_valid_tensor = [torch.from_numpy(x) for x in X_valid]\n",
    "X_test_tensor = [torch.from_numpy(x) for x in X_test]\n",
    "\n",
    "train_dataset = utilities.CustomDataset(X_train_tensor)\n",
    "valid_dataset = utilities.CustomDataset(X_valid_tensor)\n",
    "test_dataset = utilities.CustomDataset(X_test_tensor)\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset, batch_size=PARAMS['batch_size'], shuffle=True)\n",
    "valid_data_loader = DataLoader(\n",
    "    valid_dataset, batch_size=PARAMS['batch_size'], shuffle=False)\n",
    "test_data_loader = DataLoader(\n",
    "    test_dataset, batch_size=PARAMS['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the lambda parameter\n",
    "lambda_ = 0.8\n",
    "sync_head_conv_parameters = sync_head_utils.initialize_parameters(\n",
    "    SENSORS, WINDOW_LENGTHS, NUM_CHANNELS, lambda_=lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------\n",
    "# A UNIFIED FC HEAD FOR (N, C, L_in) --> (N, C, L_out)\n",
    "# --------------------------------------------------------------------------------\n",
    "class create_fc_head(nn.Module):\n",
    "    \"\"\"\n",
    "    A fully-connected (FC) head that operates channel by channel.\n",
    "\n",
    "    This can be used for:\n",
    "      - Synchronization: map from a sensor's raw length L_sensor to a common length L_common.\n",
    "      - Projection: map from the common length L_common back to L_sensor.\n",
    "    \n",
    "    Shape:\n",
    "        - Input:  (N, C, L_in)\n",
    "        - Output: (N, C, L_out)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, output_size, num_channels, num_layers):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_size (int): L_in\n",
    "            output_size (int): L_out\n",
    "            num_channels (int): C\n",
    "            num_layers (int): number of FC layers per channel\n",
    "        \"\"\"\n",
    "        super(create_fc_head, self).__init__()\n",
    "        self.fc_stacks = nn.ModuleList()\n",
    "\n",
    "        # Create channel-specific FC stacks\n",
    "        for _ in range(num_channels):\n",
    "            layers = []\n",
    "            current_size = input_size\n",
    "            for layer_idx in range(num_layers):\n",
    "                # FC layer\n",
    "                fc = nn.Linear(current_size, output_size)\n",
    "                layers.append(fc)\n",
    "\n",
    "                # Add ReLU + BatchNorm except after the last layer\n",
    "                if layer_idx < num_layers - 1:\n",
    "                    layers.append(nn.ReLU())\n",
    "                    layers.append(nn.BatchNorm1d(output_size))\n",
    "\n",
    "                current_size = output_size\n",
    "\n",
    "            # Wrap in a Sequential\n",
    "            self.fc_stacks.append(nn.Sequential(*layers))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (torch.Tensor): (N, C, L_in)\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: (N, C, L_out)\n",
    "        \"\"\"\n",
    "        outputs = []\n",
    "        for c in range(x.size(1)):\n",
    "            # Channel slice => (N, L_in)\n",
    "            channel_input = x[:, c, :]\n",
    "            channel_output = self.fc_stacks[c](channel_input)  # (N, L_out)\n",
    "            outputs.append(channel_output.unsqueeze(1))        # (N, 1, L_out)\n",
    "\n",
    "        # Concat the per-channel outputs => (N, C, L_out)\n",
    "        return torch.cat(outputs, dim=1)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# UTILITY CLASSES / FUNCTIONS\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "class MaskOutOneChannel(nn.Module):\n",
    "    \"\"\"\n",
    "    For an input of shape (B, C_total, L), this module produces a \n",
    "    concatenation of masked versions. For each block of width c_sync,\n",
    "    we omit that block and keep the rest, repeating for all channel blocks.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sensors, num_channels, c_sync):\n",
    "        super(MaskOutOneChannel, self).__init__()\n",
    "        self.sensors = sensors\n",
    "        self.num_channels_dict = num_channels\n",
    "        self.c_sync = c_sync\n",
    "\n",
    "        # total_channels = sum of sensor channels\n",
    "        self.total_channels = sum(num_channels.values())\n",
    "        # So total input channels = total_channels * c_sync\n",
    "        self.total_c = self.total_channels * self.c_sync\n",
    "\n",
    "        self.register_buffer('final_indices', self._create_indices())\n",
    "\n",
    "    def _create_indices(self):\n",
    "        \"\"\"\n",
    "        For each channel block of width c_sync, omit that block\n",
    "        and keep the others. Then concatenate for all blocks.\n",
    "        \"\"\"\n",
    "        all_indices = []\n",
    "        for ch in range(self.total_channels):\n",
    "            remove_start = ch * self.c_sync\n",
    "            remove_end = remove_start + self.c_sync\n",
    "            keep_indices = list(range(0, remove_start)) + \\\n",
    "                           list(range(remove_end, self.total_c))\n",
    "            all_indices.extend(keep_indices)\n",
    "        return torch.tensor(all_indices, dtype=torch.long)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: shape (B, C_total, L)\n",
    "        returns: shape (B, C_total*(C_total - c_sync), L)\n",
    "        \"\"\"\n",
    "        return x.index_select(dim=1, index=self.final_indices)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# SYNCHRONIZATION BLOCK\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "class SynchronizationBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Resamples/synchronizes each sensorâ€™s data to a common length L_common.\n",
    "    Multiple methods: 'sync_head_conv', 'sync_head_fc', 'resample_interp', etc.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sensors,\n",
    "        num_channels,\n",
    "        c_sync,\n",
    "        sync_head_conv_parameters,\n",
    "        params,\n",
    "        sync_method,\n",
    "        window_lengths,\n",
    "        fc_num_layers\n",
    "    ):\n",
    "        super(SynchronizationBlock, self).__init__()\n",
    "        self.default_device = params['device']\n",
    "\n",
    "        # L_common for conv-based might come from sync_head_conv_parameters[...]['input_2']\n",
    "        # for FC-based, you can choose an L_common or store in sync_head_conv_parameters as well\n",
    "        self.sync_window_length = sync_head_conv_parameters[\n",
    "            list(sync_head_conv_parameters.keys())[0]]['input_2']\n",
    "\n",
    "        self.total_channels = sum(num_channels.values())\n",
    "        self.c_sync = c_sync\n",
    "        self.sync_method = sync_method\n",
    "        self.window_lengths = window_lengths\n",
    "\n",
    "        if sync_method == 'sync_head_conv':\n",
    "            # Example conv-based approach (via some sync_head_utils)\n",
    "            self.sync_heads = nn.ModuleList([\n",
    "                sync_head_utils.create_synchronization_head(\n",
    "                    input_sensor_channels=num_channels[sensor],\n",
    "                    output_sensor_channels=c_sync * num_channels[sensor],\n",
    "                    groups=num_channels[sensor],\n",
    "                    parameters=sync_head_conv_parameters[sensor],\n",
    "                    type='input'\n",
    "                )\n",
    "                for sensor in sensors\n",
    "            ])\n",
    "            self._sync_fn = self._resample_sync_head_conv\n",
    "\n",
    "        elif sync_method == 'sync_head_fc':\n",
    "            # FC-based approach (unified create_fc_head)\n",
    "            self.sync_heads = nn.ModuleList([\n",
    "                create_fc_head(\n",
    "                    input_size=window_lengths[sensor],      # L_in (raw)\n",
    "                    output_size=self.sync_window_length,    # L_out (common)\n",
    "                    num_channels=num_channels[sensor],\n",
    "                    num_layers=fc_num_layers  # or more, user choice\n",
    "                )\n",
    "                for sensor in sensors\n",
    "            ])\n",
    "            self._sync_fn = self._resample_sync_head_fc\n",
    "\n",
    "        elif sync_method == 'resample_interp':\n",
    "            self.sync_heads = None\n",
    "            self._sync_fn = self._resample_interp\n",
    "\n",
    "        elif sync_method == 'resample_fft':\n",
    "            self.sync_heads = None\n",
    "            self._sync_fn = self._resample_fft\n",
    "\n",
    "        elif sync_method == 'zeropad':\n",
    "            self.sync_heads = None\n",
    "            self._sync_fn = self._resample_zeropad\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown sync_method: {sync_method}\")\n",
    "\n",
    "    def forward(self, input_data_list):\n",
    "        \"\"\"\n",
    "        input_data_list: list of (B, C_sensor, L_sensor)\n",
    "        returns: (B, C_total*c_sync, L_common)\n",
    "        \"\"\"\n",
    "        return self._sync_fn(input_data_list)\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Different synchronization methods\n",
    "    # --------------------------------------------------------------------------\n",
    "\n",
    "    def _resample_sync_head_conv(self, input_data_list):\n",
    "        # Just cat outputs from each conv-based head\n",
    "        return torch.cat([\n",
    "            head(inp) for head, inp in zip(self.sync_heads, input_data_list)\n",
    "        ], dim=1)\n",
    "\n",
    "    def _resample_sync_head_fc(self, input_data_list):\n",
    "        # Cat outputs from each fc-based head\n",
    "        return torch.cat([\n",
    "            head(inp) for head, inp in zip(self.sync_heads, input_data_list)\n",
    "        ], dim=1)\n",
    "\n",
    "    def _resample_interp(self, input_data_list):\n",
    "        input_data_list = [inp.cpu() for inp in input_data_list]\n",
    "        resampled = [\n",
    "            F.interpolate(\n",
    "                inp, size=self.sync_window_length, mode='linear'\n",
    "            ).to(self.default_device)\n",
    "            for inp in input_data_list\n",
    "        ]\n",
    "        return torch.cat(resampled, dim=1)\n",
    "\n",
    "    def _fft_resample_single(self, input_data):\n",
    "        fft_vals = torch.fft.fft(input_data, dim=-1)\n",
    "        L_new = self.sync_window_length\n",
    "        L = input_data.size(-1)\n",
    "\n",
    "        if L_new > L:\n",
    "            pad_size = L_new - L\n",
    "            fft_vals = F.pad(fft_vals, (0, pad_size), \"constant\", 0)\n",
    "        else:\n",
    "            fft_vals = fft_vals[..., :L_new]\n",
    "\n",
    "        return torch.fft.ifft(fft_vals, dim=-1).real\n",
    "\n",
    "    def _resample_fft(self, input_data_list):\n",
    "        input_data_list = [inp.cpu() for inp in input_data_list]\n",
    "        resampled = [\n",
    "            self._fft_resample_single(inp).to(self.default_device)\n",
    "            for inp in input_data_list\n",
    "        ]\n",
    "        return torch.cat(resampled, dim=1)\n",
    "\n",
    "    def _resample_zeropad(self, input_data_list):\n",
    "        padded_data = []\n",
    "        for inp in input_data_list:\n",
    "            B, C, L = inp.shape\n",
    "            if L < self.sync_window_length:\n",
    "                pad_size = self.sync_window_length - L\n",
    "                inp_padded = F.pad(inp, (0, pad_size), \"constant\", 0)\n",
    "            else:\n",
    "                inp_padded = inp[..., :self.sync_window_length]\n",
    "            padded_data.append(inp_padded)\n",
    "        return torch.cat(padded_data, dim=1)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# FUSING BLOCK (PMCE)\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "class PMCE(nn.Module):\n",
    "    \"\"\"\n",
    "    Applies two sequential convolutional blocks (with dilation & skip connections)\n",
    "    to the masked input, effectively fusing the masked representations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, total_channels, c_sync, c_fuse, kernel_size, sensors, num_channels):\n",
    "        super(PMCE, self).__init__()\n",
    "        self.total_channels = total_channels\n",
    "        self.c_sync = c_sync\n",
    "\n",
    "        # After sync, shape => (B, C_total*c_sync, L)\n",
    "        # MaskOutOneChannel => (B, (C_total-c_sync)*C_total, L)\n",
    "        self.total_input_fuse_channels = (\n",
    "            self.total_channels - 1\n",
    "        ) * self.c_sync * self.total_channels\n",
    "\n",
    "        self.total_middle_fuse_channels = self.total_input_fuse_channels * c_fuse\n",
    "\n",
    "        padding = kernel_size - 1\n",
    "        self.mask_module = MaskOutOneChannel(sensors, num_channels, c_sync)\n",
    "\n",
    "        # First fuse part\n",
    "        self.fusing_part1 = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=self.total_input_fuse_channels,\n",
    "                out_channels=self.total_middle_fuse_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding=padding,\n",
    "                dilation=2,\n",
    "                groups=self.total_channels\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(self.total_middle_fuse_channels),\n",
    "            nn.Conv1d(\n",
    "                in_channels=self.total_middle_fuse_channels,\n",
    "                out_channels=self.total_middle_fuse_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding=padding * 2,\n",
    "                dilation=4,\n",
    "                groups=self.total_channels\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(self.total_middle_fuse_channels),\n",
    "        )\n",
    "\n",
    "        # Second fuse part\n",
    "        self.fusing_part2 = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=self.total_middle_fuse_channels,\n",
    "                out_channels=self.total_middle_fuse_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding=padding * 4,\n",
    "                dilation=8,\n",
    "                groups=self.total_channels\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(self.total_middle_fuse_channels),\n",
    "            nn.Conv1d(\n",
    "                in_channels=self.total_middle_fuse_channels,\n",
    "                out_channels=self.total_channels * c_sync,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding=padding * 8,\n",
    "                dilation=16,\n",
    "                groups=self.total_channels\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(self.total_channels * c_sync),\n",
    "        )\n",
    "\n",
    "        # Residual layers\n",
    "        self.residual_conv1 = nn.Conv1d(\n",
    "            in_channels=self.total_input_fuse_channels,\n",
    "            out_channels=self.total_middle_fuse_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            groups=self.total_channels\n",
    "        )\n",
    "        self.residual_conv2 = nn.Conv1d(\n",
    "            in_channels=self.total_middle_fuse_channels,\n",
    "            out_channels=self.total_channels * c_sync,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            groups=self.total_channels\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, C_total*c_sync, L)\n",
    "\n",
    "        returns: (B, C_total*c_sync, L) fused output\n",
    "        \"\"\"\n",
    "        masked_groups = self.mask_module(x)\n",
    "\n",
    "        out_part1 = self.fusing_part1(masked_groups)\n",
    "        residual1 = self.residual_conv1(masked_groups)\n",
    "        out_part1 = out_part1 + residual1\n",
    "\n",
    "        out_part2 = self.fusing_part2(out_part1)\n",
    "        residual2 = self.residual_conv2(out_part1)\n",
    "        out_part2 = out_part2 + residual2\n",
    "\n",
    "        return out_part2\n",
    "\n",
    "# RMCE\n",
    "\n",
    "class RMCE(nn.Module):\n",
    "    \"\"\"\n",
    "    Applies two sequential convolutional blocks (with dilation & skip connections)\n",
    "    to the masked input, effectively fusing the masked representations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, total_channels, c_sync, c_fuse, kernel_size, sensors, num_channels):\n",
    "        super(RMCE, self).__init__()\n",
    "        self.total_channels = total_channels\n",
    "        self.c_sync = c_sync\n",
    "\n",
    "        padding = kernel_size - 1\n",
    "        self.total_middle_fuse_channels=total_channels*c_fuse\n",
    "        # First fuse part\n",
    "        self.fusing_part1 = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=self.total_channels * c_sync,\n",
    "                out_channels=self.total_middle_fuse_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding=padding,\n",
    "                dilation=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(self.total_middle_fuse_channels),\n",
    "            nn.Conv1d(\n",
    "                in_channels=self.total_middle_fuse_channels,\n",
    "                out_channels=self.total_middle_fuse_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding=padding * 2,\n",
    "                dilation=4\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(self.total_middle_fuse_channels),\n",
    "        )\n",
    "\n",
    "        # Second fuse part\n",
    "        self.fusing_part2 = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=self.total_middle_fuse_channels,\n",
    "                out_channels=self.total_middle_fuse_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding=padding * 4,\n",
    "                dilation=8\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(self.total_middle_fuse_channels),\n",
    "            nn.Conv1d(\n",
    "                in_channels=self.total_middle_fuse_channels,\n",
    "                out_channels=self.total_channels * c_sync,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding=padding * 8,\n",
    "                dilation=16\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(self.total_channels * c_sync),\n",
    "        )\n",
    "\n",
    "        # Residual layers\n",
    "        self.residual_conv1 = nn.Conv1d(\n",
    "            in_channels=self.total_channels * c_sync,\n",
    "            out_channels=self.total_middle_fuse_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1\n",
    "        )\n",
    "        self.residual_conv2 = nn.Conv1d(\n",
    "            in_channels=self.total_middle_fuse_channels,\n",
    "            out_channels=self.total_channels * c_sync,\n",
    "            kernel_size=1,\n",
    "            stride=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, C_total*c_sync, L)\n",
    "\n",
    "        returns: (B, C_total*c_sync, L) fused output\n",
    "        \"\"\"\n",
    "        # generate random mask randomly masking out some channels of some sensors B, C, L\n",
    "        mask = torch.rand(size=(x.shape[0], x.shape[1], x.shape[2]), dtype=torch.float32).to(x.device) > 0.95\n",
    "        x = x * mask\n",
    "\n",
    "        out_part1 = self.fusing_part1(x)\n",
    "        residual1 = self.residual_conv1(x)\n",
    "        out_part1 = out_part1 + residual1\n",
    "\n",
    "        out_part2 = self.fusing_part2(out_part1)\n",
    "        residual2 = self.residual_conv2(out_part1)\n",
    "        out_part2 = out_part2 + residual2\n",
    "\n",
    "        return out_part2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# PROJECTION BLOCK\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "class ProjectionBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Projects the fused representation (common length L_common)\n",
    "    back to each sensor's original length L_sensor (or to any desired L_out).\n",
    "    Multiple methods: 'conv' or 'fc'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sensors,\n",
    "        num_channels,\n",
    "        c_sync,\n",
    "        sync_head_conv_parameters,\n",
    "        projection_method='conv',\n",
    "        fc_num_layers=1,\n",
    "        window_lengths=None\n",
    "    ):\n",
    "        super(ProjectionBlock, self).__init__()\n",
    "        self.sensors = sensors\n",
    "        self.num_channels = num_channels\n",
    "        self.c_sync = c_sync\n",
    "        self.total_channels = sum(num_channels.values())\n",
    "\n",
    "        # For slicing out each sensor's portion from the fused feature map\n",
    "        channel_sizes = [num_channels[sensor] * self.c_sync for sensor in sensors]\n",
    "        cumulative_offsets = [0] + list(accumulate(channel_sizes))[:-1]\n",
    "        self.proj_slices = [\n",
    "            slice(start, start + size)\n",
    "            for start, size in zip(cumulative_offsets, channel_sizes)\n",
    "        ]\n",
    "\n",
    "        self.proj_heads = nn.ModuleList()\n",
    "        if projection_method == 'conv':\n",
    "            # Use existing sync_head_utils in \"output\" mode (conv-based)\n",
    "            for sensor in sensors:\n",
    "                out_params = sync_head_utils.invert_synchronization_head_parameters(\n",
    "                    sync_head_conv_parameters[sensor]\n",
    "                )\n",
    "                proj_head = sync_head_utils.create_synchronization_head(\n",
    "                    input_sensor_channels=c_sync * num_channels[sensor],\n",
    "                    output_sensor_channels=num_channels[sensor],\n",
    "                    groups=num_channels[sensor],\n",
    "                    parameters=out_params,\n",
    "                    type='output'\n",
    "                )\n",
    "                self.proj_heads.append(proj_head)\n",
    "            self._proj_fn = self._proj_fn_conv\n",
    "\n",
    "        elif projection_method == 'fc':\n",
    "            # Use the unified FC-based approach\n",
    "            if window_lengths is None:\n",
    "                raise ValueError(\"For 'fc' projection, you need `window_lengths`.\")\n",
    "            for sensor in sensors:\n",
    "                L_common = sync_head_conv_parameters[sensor]['input_2']\n",
    "                L_sensor = window_lengths[sensor]\n",
    "                proj_head = create_fc_head(\n",
    "                    input_size=L_common,\n",
    "                    output_size=L_sensor,\n",
    "                    num_channels=num_channels[sensor],\n",
    "                    num_layers=fc_num_layers\n",
    "                )\n",
    "                self.proj_heads.append(proj_head)\n",
    "            self._proj_fn = self._proj_fn_fc\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown projection_method: {projection_method}\")\n",
    "\n",
    "    def forward(self, fused_output):\n",
    "        \"\"\"\n",
    "        fused_output: (B, C_total*c_sync, L_common)\n",
    "        returns: list of (B, C_sensor, L_sensor), one for each sensor\n",
    "        \"\"\"\n",
    "        return self._proj_fn(fused_output)\n",
    "\n",
    "    def _proj_fn_conv(self, fused_output):\n",
    "        sensor_projections = []\n",
    "        for proj_head, sl in zip(self.proj_heads, self.proj_slices):\n",
    "            sensor_out = proj_head(fused_output[:, sl, :])\n",
    "            sensor_projections.append(sensor_out)\n",
    "        return sensor_projections\n",
    "\n",
    "    def _proj_fn_fc(self, fused_output):\n",
    "        sensor_projections = []\n",
    "        for proj_head, sl in zip(self.proj_heads, self.proj_slices):\n",
    "            sensor_out = proj_head(fused_output[:, sl, :])\n",
    "            sensor_projections.append(sensor_out)\n",
    "        return sensor_projections\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# MAIN MODEL\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "class SynchronMaskEstimator(nn.Module):\n",
    "    \"\"\"\n",
    "    A neural network module that:\n",
    "      1) Synchronizes input sensor data to a common window length (L_common).\n",
    "      2) Passes these masked versions through a fusing block (PMCE).\n",
    "      3) Desyncronises the fused representation back to each sensor's space (L_sensor).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sensors,\n",
    "        num_channels,\n",
    "        window_lengths,\n",
    "        c_sync,\n",
    "        c_fuse,\n",
    "        kernel_size,\n",
    "        params,\n",
    "        sync_method,\n",
    "        sync_head_conv_parameters,\n",
    "        projection_method='conv',\n",
    "        fc_num_layers=1\n",
    "    ):\n",
    "        super(SynchronMaskEstimator, self).__init__()\n",
    "        self.sensors = sensors\n",
    "        self.num_channels_dict = num_channels\n",
    "        self.c_sync = c_sync\n",
    "        self.c_fuse = c_fuse\n",
    "        self.kernel_size = kernel_size\n",
    "        self.params = params\n",
    "        self.default_device = params['device']\n",
    "        self.total_channels = sum(num_channels.values())\n",
    "\n",
    "        # 1) Synchronization block\n",
    "        self.synchronizer = SynchronizationBlock(\n",
    "            sensors=sensors,\n",
    "            num_channels=num_channels,\n",
    "            c_sync=c_sync,\n",
    "            sync_head_conv_parameters=sync_head_conv_parameters,\n",
    "            params=params,\n",
    "            sync_method=sync_method,\n",
    "            window_lengths=window_lengths,\n",
    "            fc_num_layers=fc_num_layers\n",
    "        )\n",
    "\n",
    "        # 2) Fusing block\n",
    "        self.fusing_block = RMCE(\n",
    "            total_channels=self.total_channels,\n",
    "            c_sync=self.c_sync,\n",
    "            c_fuse=self.c_fuse,\n",
    "            kernel_size=self.kernel_size,\n",
    "            sensors=self.sensors,\n",
    "            num_channels=self.num_channels_dict\n",
    "        )\n",
    "\n",
    "        # 3) Projection block\n",
    "        self.projection_block = ProjectionBlock(\n",
    "            sensors=sensors,\n",
    "            num_channels=num_channels,\n",
    "            c_sync=c_sync,\n",
    "            sync_head_conv_parameters=sync_head_conv_parameters,\n",
    "            projection_method=projection_method,\n",
    "            fc_num_layers=fc_num_layers,\n",
    "            window_lengths=window_lengths\n",
    "        )\n",
    "\n",
    "    def forward(self, input_data_list):\n",
    "        \"\"\"\n",
    "        input_data_list: list of (B, C_sensor, L_sensor)\n",
    "        returns: list of (B, C_sensor, L_sensor)\n",
    "        \"\"\"\n",
    "        # Step 1: Synchronize & concat => (B, C_total*c_sync, L_common)\n",
    "        synced_data = self.synchronizer(input_data_list)\n",
    "\n",
    "        # Step 2 & 3: Fuse => (B, C_total*c_sync, L_common)\n",
    "        fused_output = self.fusing_block(synced_data)\n",
    "\n",
    "        # Step 4: Project back => list of (B, C_sensor, L_sensor)\n",
    "        sensor_outputs = self.projection_block(fused_output)\n",
    "\n",
    "        return sensor_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_sync = 1\n",
    "C_fuse = 1\n",
    "kernel_size = 3\n",
    "model = SynchronMaskEstimator(sensors=SENSORS,\n",
    "                              num_channels=NUM_CHANNELS,\n",
    "                              window_lengths=WINDOW_LENGTHS,\n",
    "                              c_sync=C_sync,\n",
    "                              c_fuse=C_fuse,\n",
    "                              kernel_size=kernel_size,\n",
    "                              params=PARAMS,\n",
    "                              sync_method='sync_head_conv',# 'sync_head_conv', 'sync_head_fc' , 'resample_interp', 'resample_fft', 'zeropad'\n",
    "                              sync_head_conv_parameters=sync_head_conv_parameters,\n",
    "                              projection_method='conv', # 'fc' or 'conv',\n",
    "                              fc_num_layers=1\n",
    "                              ).to(PARAMS['device'])\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=PARAMS['lr'])\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")\n",
    "# Calculate number of trainable parameters\n",
    "trainable_params = sum(p.numel()\n",
    "                       for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total number of trainable parameters: {trainable_params}\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = float('inf')\n",
    "non_improving_count = 0\n",
    "best_model = None\n",
    "train_losses_epoch = []\n",
    "valid_losses_epoch = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    print('----------- Epoch', epoch + 1, '-----------')\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    total_valid_loss = 0.0\n",
    "    loader = tqdm.tqdm(train_data_loader)\n",
    "    for batch_idx, x_batch in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        x_batch = [x.to(PARAMS['device']) for x in x_batch]\n",
    "        x_batch_output = model(x_batch)\n",
    "        sensor_losses = torch.cat([((x_sensor - x_sensor_out)**2).mean(0).mean(1)\n",
    "                                  for x_sensor, x_sensor_out in zip(x_batch, x_batch_output)])\n",
    "        loss = sum(sensor_losses)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "        avg_train_loss = total_train_loss / (batch_idx+1)\n",
    "        loader.set_postfix({'Train_loss': avg_train_loss})\n",
    "    train_losses_epoch.append(avg_train_loss)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loader = tqdm.tqdm(valid_data_loader)\n",
    "        for batch_idx, x_batch in enumerate(loader):\n",
    "            x_batch = [x.to(PARAMS['device']) for x in x_batch]\n",
    "            x_batch_output = model(x_batch)\n",
    "            sensor_losses = sensor_losses = torch.cat([((x_sensor - x_sensor_out)**2).mean(\n",
    "                0).mean(1) for x_sensor, x_sensor_out in zip(x_batch, x_batch_output)])\n",
    "            loss = sum(sensor_losses)\n",
    "            total_valid_loss += loss.item()\n",
    "            avg_val_loss = total_valid_loss / (batch_idx+1)\n",
    "            loader.set_postfix({'Valid_loss': avg_val_loss})\n",
    "        valid_losses_epoch.append(avg_val_loss)\n",
    "\n",
    "        # Check if current validation loss is less than the best found so far\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            best_model = model.state_dict()  # Save the best model\n",
    "            non_improving_count = 0  # Reset the counter\n",
    "        else:\n",
    "            non_improving_count += 1  # Increment the counter since there is no improvement\n",
    "\n",
    "        # Stop training if validation loss has not improved for more than 4 epochs\n",
    "        if non_improving_count > PARAMS['patience']:\n",
    "            print(\"Stopping early due to no improvement in validation loss.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch = next(valid_data_loader.__iter__())\n",
    "x_batch_t = [x.to(PARAMS['device']) for x in x_batch.copy()]\n",
    "x_batch_output = model(x_batch_t)\n",
    "\n",
    "sensor_zero_out = 0\n",
    "x_batch_t_zeros = [x.clone() for x in x_batch_t]\n",
    "x_batch_t_zeros[sensor_zero_out][:, :, :] = torch.randn_like(\n",
    "    x_batch_t_zeros[sensor_zero_out][:, :, :])\n",
    "# zero out one sensor\n",
    "# x_batch_t_zeros[sensor_zero_out][:,:,:] = torch.zeros_like(x_batch_t_zeros[sensor_zero_out][:,:,:])\n",
    "\n",
    "x_batch_output_zeros = model(x_batch_t_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute MSE of normal and 1 masked sensor version\n",
    "sensor_losses = torch.cat([((x_sensor - x_sensor_out)**2).mean(0).mean(1)\n",
    "                          for x_sensor, x_sensor_out in zip(x_batch_t, x_batch_output)]).cpu().detach().numpy()\n",
    "sensor_losses_zeros = torch.cat([((x_sensor - x_sensor_out)**2).mean(0).mean(1)\n",
    "                                for x_sensor, x_sensor_out in zip(x_batch_t, x_batch_output_zeros)]).cpu().detach().numpy()\n",
    "# print the MSE of the normal and masked sensor version\n",
    "print(sensor_losses)\n",
    "print(sensor_losses_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample = np.random.randint(0, PARAMS['batch_size'])\n",
    "total_plot = sum([NUM_CHANNELS[sensor] for sensor in SENSORS])\n",
    "plt.close('all')\n",
    "fig, axs = plt.subplots(total_plot, 1, figsize=(\n",
    "    WIDTH, HEIGHT * total_plot * 0.7), sharex=True)\n",
    "\n",
    "i = 0\n",
    "overall_MSE = 0\n",
    "for sensor_idx, sensor in enumerate(SENSORS):\n",
    "    for channel_idx in range(NUM_CHANNELS[sensor]):\n",
    "        t = np.linspace(0, 1, WINDOW_LENGTHS[sensor])\n",
    "        input = x_batch_t[sensor_idx][sample, channel_idx].cpu().numpy()\n",
    "        output = x_batch_output[sensor_idx][sample,\n",
    "                                            channel_idx].detach().cpu().numpy()\n",
    "        output_zeros = x_batch_output_zeros[sensor_idx][sample, channel_idx].detach(\n",
    "        ).cpu().numpy()\n",
    "        # print loss on output and output_zeros\n",
    "        loss_output = ((input - output)**2).mean(0)\n",
    "        loss_output_zeros = ((input - output_zeros)**2).mean(0)\n",
    "\n",
    "        print(f\"Sensor:{sensor}, Channel:{channel_idx}, Loss on output: {\n",
    "              loss_output}, Loss on output_zeros: {loss_output_zeros}\")\n",
    "\n",
    "        axs[i].plot(t, input, label='Input')\n",
    "        axs[i].plot(t, output, label='Output')\n",
    "        axs[i].plot(t, output_zeros, label='Output (Random)')\n",
    "        i += 1\n",
    "        overall_MSE += loss_output\n",
    "print(f\"Overall MSE: {overall_MSE}\")\n",
    "plt.tight_layout()\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
